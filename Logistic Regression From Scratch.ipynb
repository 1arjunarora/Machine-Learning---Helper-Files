{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will write logistic regression algorithm from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "data = sm.datasets.fair.load_pandas().data\n",
    "data['affairs'] = (data.affairs > 0).astype(int)\n",
    "\n",
    "x = data.drop('affairs', axis = 1)\n",
    "y = data['affairs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class logisticRegression():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.coef = 0\n",
    "        \n",
    "    def sigmoid(self, array):\n",
    "       \n",
    "        self.array = array\n",
    "        \n",
    "        coef_times_inputs = np.dot(array,self.coef)\n",
    "        preds = (1/(1+np.exp(-coef_times_inputs))).round(3)\n",
    "        return preds\n",
    "        \n",
    "    def fit(self, x, y, alpha, threshold):\n",
    "        \n",
    "        #1 no of rows check\n",
    "        if x.shape[0] == y.shape[0]:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError('Number of rows in x and y do not match') \n",
    "        \n",
    "        #2 missing value check\n",
    "        if sum(x.isnull().sum()) or sum(y.isnull()) > 0:\n",
    "            raise ValueError('Missing value in data')\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        #3 categorical columns in data\n",
    "        if len(x.select_dtypes(include = ['object']).columns) > 0 or y.dtype == 'object':\n",
    "            raise ValueError('Categorical columns exist in data')\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        #4 convert to numpy array\n",
    "        transform_x = np.asarray(x)\n",
    "        transform_y = np.asarray(y)        \n",
    "     \n",
    "        #5 add bias to the data\n",
    "        bias = np.ones((transform_x.shape[0],1))\n",
    "        transform_x = np.concatenate((bias, transform_x), axis = 1)\n",
    "        \n",
    "        #6 init coeff for all columns + bias\n",
    "        self.coef = np.random.uniform(low=-1, high=1, size=(transform_x.shape[1])) \n",
    "\n",
    "        #7 list for cost values for each iteration\n",
    "        list_cost = []\n",
    "        \n",
    "        #8 main function ===============================================================================\n",
    "        \n",
    "        iteration = 1\n",
    "    \n",
    "        while (iteration < 100):\n",
    "\n",
    "            if (iteration <= 5):\n",
    "\n",
    "                # predict values\n",
    "                \n",
    "                coef_times_inputs = np.dot(transform_x,self.coef)\n",
    "                preds = (1/(1+np.exp(-coef_times_inputs))).round(3)\n",
    "                \n",
    "                # error \n",
    "                error = transform_y - preds \n",
    "\n",
    "                # cost function\n",
    "                cost = np.sum((-transform_y+0.0001)*np.log(preds+0.0001) - (1-transform_y)*np.log(1-preds+0.0001))/transform_x.shape[0]\n",
    "\n",
    "                list_cost.append(cost)\n",
    "\n",
    "                # gradient\n",
    "                gradient = np.dot(transform_x.T, error) / transform_x.shape[0]\n",
    "                \n",
    "                # update coefficients \n",
    "                self.coef = self.coef - alpha*gradient\n",
    "\n",
    "                # update alpha\n",
    "                alpha = alpha*0.95\n",
    "\n",
    "                \n",
    "            # for iterations more than 5, check threshold value criteria\n",
    "            else:\n",
    "                if (float(sum(list_cost[-5:]))/5 - list_cost[-1]) < threshold:\n",
    "                    pass\n",
    "                \n",
    "                else:\n",
    "                    # predict values\n",
    "     \n",
    "                    coef_times_inputs = np.dot(transform_x,self.coef)\n",
    "                    preds = (1/(1+np.exp(-coef_times_inputs))).round(3)\n",
    "                    \n",
    "                    # error \n",
    "                    error = transform_y - preds \n",
    "\n",
    "                    # cost function\n",
    "                    cost = np.sum((-transform_y+0.0001)*np.log(preds+0.0001) - (1-transform_y)*np.log(1-preds+0.0001))/transform_x.shape[0]\n",
    "\n",
    "                    list_cost.append(cost)\n",
    "\n",
    "                    # gradient\n",
    "                    gradient = np.dot(transform_x.T, error) / transform_x.shape[0]\n",
    "\n",
    "                    # update coefficients \n",
    "                    self.coef = self.coef - alpha*gradient\n",
    "\n",
    "                    # update alpha\n",
    "                    alpha = alpha*0.95\n",
    "\n",
    "            # increment iterations\n",
    "            iteration = iteration + 1\n",
    "           # print iteration, cost\n",
    "            \n",
    "        \"\"\"\n",
    "        x: input pandas dataframe\n",
    "        y: output pandas series (Class labels)\n",
    " \n",
    "        step1: Check if the number of rows in x and y are the same. If not raise a value error with a message.\n",
    "        \n",
    "        step2: Check if there is any missing value in the dataset (both for x and y). \n",
    "               If there is, raise a value error with a message.\n",
    "               \n",
    "        step3: Check if there is any categorical value in x or y. If there is, raise a value error with a message.\n",
    "        \n",
    "        step4: Transform both x and y into numpy.arrays (it is easier to work with arrays for matrix operations).\n",
    "        \n",
    "        step5: Add bias to the input vector x. bias means add a column which is 1 across al the rows.\n",
    "               This will increase the number of columns of x by 1. x.shape[1] will increase by 1.\n",
    "               \n",
    "        step6: initialize self.coef.\n",
    "                \n",
    "        step7: create a list to save the cost values for each iteration.\n",
    "        \n",
    "        step8: while not converged and iteration number > 10000\n",
    "                    calculate the predicted values\n",
    "                    calculate the error \n",
    "                    calculate the cost function and append it to the cost list\n",
    "                    calculate the gradient in a way that gradient is \n",
    "                                      gradient = (t(x) * (error))/(size_of_x) (number of rows)\n",
    "                    adjust the coef in a way that\n",
    "                                        coef = coef - alpha*gradient\n",
    "                    adjust alpha in a way that\n",
    "                                        alpha = alpha*0.95\n",
    "                    \n",
    "        step 8: Check if the convergence criteria is satisfied:\n",
    "                if you iterate at least as many times 10000\n",
    "                if the difference between the average of the last 5 cost values and the last cost value \n",
    "                is less than the threshold.\n",
    "        \n",
    "        You will not need to return anything because you are working on the coefs, which are class attributes\n",
    "        \"\"\"\n",
    "    \n",
    "    def predict_prob(self, x):\n",
    "        \n",
    "        # transform x\n",
    "        transform_x = np.asarray(x)\n",
    "\n",
    "        #5 add bias to the data\n",
    "        bias = np.ones((transform_x.shape[0],1))\n",
    "        transform_x = np.concatenate((bias, transform_x), axis = 1)\n",
    "        \n",
    "        if transform_x.shape[1] == self.coef.shape[0]:\n",
    "            preds = self.sigmoid(transform_x)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError('size of input array does not match coefficients')\n",
    "        \n",
    "        return preds\n",
    " \n",
    "        \"\"\"\n",
    "        Convert x into numpy aray and add bias\n",
    "        Check if size of self.coef is the same with the number of columns in x\n",
    "        Using x and self.coef, make the predictions\n",
    "        \"\"\"\n",
    "    \n",
    "    def predict_class(self, x):\n",
    "        \n",
    "        prob_x = self.predict_prob(x)\n",
    "        \n",
    "        prob_x[prob_x>0.5] = 1\n",
    "        prob_x[prob_x<=0.5] = 0\n",
    "        \n",
    "        return prob_x\n",
    "\n",
    "        \"\"\"\n",
    "        Make discrete predictions. Instead of returning probabilities return 0 or 1.\n",
    "        \"\"\"\n",
    "    \n",
    "    def get_accuracy(self, x, y):\n",
    "        \n",
    "        #pred = 0\n",
    "        pred = self.predict_class(x)\n",
    "        accuracy = float(sum(np.equal(pred,(np.asarray(y)))))/y.shape[0]\n",
    "        print accuracy\n",
    "                               \n",
    "        \"\"\"\n",
    "        Calculate the accuracy rate\n",
    "        number of true classification/total number of instances\n",
    "        number of true classification is True positive + True negative\n",
    "        \"\"\"\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
