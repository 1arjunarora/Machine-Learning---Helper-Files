{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML Tool - Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =========================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will help automate required and mundane tasks of the model building process - data cleaning, feature engineering and feature selection. The notebook assumes that some data exploration and data understanding has been done. The automated tasks conducted are as follows:\n",
    "\n",
    "1. Drop columns with high % of missing values (threshold can be edited)\n",
    "2. Drop numerical columns with no variance (means all observations are same)\n",
    "3. Drop categorical columns with all same labels\n",
    "4. Drop categorical columns with too many labels (threshold can be edited)\n",
    "5. Impute Missing Values for numerical and categorical data\n",
    "6. Encode Target Column to numerical\n",
    "7. Categorical variables: convert strings to numbers\n",
    "8. Transforms numerical values in a way that it will increase model accuracy\n",
    "9. Remove highly correlated features (similar features provide no additional value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "class Automl_tool():\n",
    "    \n",
    "    def drop_missing_columns(self, df, threshold):      \n",
    "        self.df = df\n",
    "        self.threshold = threshold\n",
    "                \n",
    "        for i in df.columns:\n",
    "            # calculating threshold\n",
    "            counter = 0\n",
    "            number_of_rows = df.shape[0]\n",
    "            number_missing = sum(pd.isnull(df[i]))\n",
    "            counter = number_missing/ (number_of_rows * 1.0)\n",
    "            \n",
    "            # dropping columns\n",
    "            if counter > threshold:\n",
    "                df.drop([i], axis = 1, inplace=True) \n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        return df\n",
    "    \n",
    "        \"\"\"\n",
    "        Objective: Drops columns most of whose rows missing\n",
    "        \n",
    "        Inputs:\n",
    "        1. Dataframe df: Pandas dataframe\n",
    "        2. threshold: Determines which columns will be dropped.\n",
    "                      if threshold is .9, the columns with 90% missing value will be dropped\n",
    "        \n",
    "        Outputs:\n",
    "        1. Dataframe df with dropped columns (if no columns are dropped, you will return the same dataframe)\n",
    "        \"\"\"\n",
    "\n",
    "    def drop_zero_variance_columns(self, df):\n",
    "        \n",
    "        self.df = df      \n",
    "        numeric_cols = df.select_dtypes(include = ['float64', 'float32', 'int64']).columns\n",
    "        for i in numeric_cols:  \n",
    "            if df[i].std() == 0.0:\n",
    "                df.drop([i], axis = 1, inplace=True)\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        return df\n",
    "        \n",
    "        \"\"\"\n",
    "        Objective: Drops numerical columns with zero variance\n",
    "        \n",
    "        Inputs:\n",
    "        1. Dataframe df: Pandas dataframe\n",
    "        \n",
    "        Outputs:\n",
    "        1. Dataframe df with dropped columns (if no columns are dropped, you will return the same dataframe)\n",
    "        \"\"\"\n",
    "        \n",
    "    def drop_zero_cardinality_columns(self, df):\n",
    "        \n",
    "        self.df = df\n",
    "        categorical_cols = df.select_dtypes(include = ['object']).columns\n",
    "        for i in categorical_cols:     \n",
    "            if df[i].min() == df[i].max():\n",
    "                df.drop([i], axis = 1, inplace=True)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "        return df\n",
    "        \n",
    "        \"\"\"\n",
    "        Objective: Drops categorical columns with same levels, such as a column with all 'yes' values\n",
    "        \n",
    "        Inputs:\n",
    "        1. Dataframe df: Pandas dataframe\n",
    "        \n",
    "        Outputs:\n",
    "        1. Dataframe df with dropped columns (if no columns are dropped, you will return the same dataframe)\n",
    "        \"\"\"        \n",
    "        \n",
    "    def drop_high_levels(self, df, threshold):\n",
    "        \n",
    "        self.df = df\n",
    "        self.threshold = threshold\n",
    "        \n",
    "        categorical_cols = df.select_dtypes(include = ['object']).columns\n",
    "        for i in categorical_cols:     \n",
    "            if len(df[i].value_counts()) > threshold:\n",
    "                df.drop([i], axis = 1, inplace=True)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "        return df\n",
    "                \n",
    "        \"\"\"\n",
    "        this task will eliminate categorical columns if this column has a lot of levels. \n",
    "        inputs:\n",
    "        1. Dataframe df: Pandas dataframe\n",
    "        2. Threshold: How many levels you want at most\n",
    "        \n",
    "        outputs:\n",
    "        1. Dataframe df: updated dataframe without dropped columns\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "    def replace_missing(self, df, num_val):\n",
    "        \n",
    "        self.df = df\n",
    "        self.num_val = num_val\n",
    "        \n",
    "        if num_val == 'mode':\n",
    "            df[df.select_dtypes(include = ['float64','float32', 'int']).columns.tolist()] = df[df.select_dtypes(include = ['float64','float32', 'int']).columns.tolist()].fillna(value = df[df.select_dtypes(include = ['float64','float32', 'int']).columns.tolist()].mode())\n",
    "        \n",
    "        elif num_val == 'mean':\n",
    "            df[df.select_dtypes(include = ['float64','float32', 'int']).columns.tolist()] = df[df.select_dtypes(include = ['float64','float32', 'int']).columns.tolist()].fillna(value = df[df.select_dtypes(include = ['float64','float32', 'int']).columns.tolist()].mean())\n",
    "        \n",
    "        elif num_val == 'median':\n",
    "            df[df.select_dtypes(include = ['float64','float32', 'int']).columns.tolist()] = df[df.select_dtypes(include = ['float64','float32', 'int']).columns.tolist()].fillna(value = df[df.select_dtypes(include = ['float64','float32', 'int']).columns.tolist()].median())\n",
    "        else:\n",
    "            df[df.select_dtypes(include = ['float64','float32', 'int']).columns.tolist()] = df[df.select_dtypes(include = ['float64','float32', 'int']).columns.tolist()].fillna(value = 0, inplace = True)\n",
    "        \n",
    "        df[df.select_dtypes(include = ['object']).columns.tolist()] = df[df.select_dtypes(include = ['object']).columns.tolist()].fillna(value = 'unknown')\n",
    "        \n",
    "        return df\n",
    "    \n",
    "        \"\"\"\n",
    "        Objective: Replaces missing values with given values\n",
    "        \n",
    "        Inputs:\n",
    "        1. Dataframe df: Pandas dataframe\n",
    "        2. num_val: User decides with what values they want to replace the missing numerical values. \n",
    "                    This value can be mean median mode or zero\n",
    "        3. cat_val: User decides with what values they want to replace the missing numerical values. \n",
    "                    This value can be mode or 'unknown'\n",
    "        \n",
    "        Outputs:\n",
    "        1. Dataframe df with imputed missing values\n",
    "        \"\"\"\n",
    "    \n",
    "    def encode_target(self, df, target_name):\n",
    "        \n",
    "        if df[target_name].dtype == 'object':\n",
    "            target_levels_cat = df[target_name].value_counts().index.tolist()\n",
    "            target_levels_num = []\n",
    "            for i in range(0, len(target_levels_cat)):\n",
    "                target_levels_num.append(i)\n",
    "                target_levels = pd.DataFrame([target_levels_cat,target_levels_num ]).T\n",
    "            target_levels.columns = ['target_level_cat', 'target_level_num']\n",
    "            \n",
    "        if df[target_name].dtype == 'object':\n",
    "            for i in range(0, target_levels.shape[0]):\n",
    "                df.loc[df[target_name] == target_levels['target_level_cat'][i], target_name] = target_levels['target_level_num'][i]\n",
    "            \n",
    "            df[target_name] = df[target_name].astype(float)\n",
    "            \n",
    "        return df\n",
    "         \n",
    "        \"\"\"\n",
    "        Objective: Encodes the class label if class column is categorical.\n",
    "                   If class column is numerical just return the same dataframe without doing anything\n",
    "                   Class label might have more than 2 levels (yes and no is two levels)\n",
    "                   Target levels can be agree, stringly agree, disagree strongly disagree, neutral (5 levels)\n",
    "                   \n",
    "        Inputs: \n",
    "        1. Dataframe df: Pandas dataframe\n",
    "        \n",
    "        Outputs:\n",
    "        1. Dataframe df with encoded binary class labels. \n",
    "        \"\"\"\n",
    "        \n",
    "    def transform(self, df, label_name):\n",
    "        \n",
    "        self.df = df\n",
    "        self.label_name = label_name\n",
    "        \n",
    "        numeric_cols = df.select_dtypes(include = ['float64', 'float32', 'int64','uint']).columns\n",
    "        for i in numeric_cols:\n",
    "        \n",
    "            # initial dictionary\n",
    "            corr = {'asis':0,'sqrt':0, 'log':0, 'pow2':0}\n",
    "\n",
    "            # asis correlation\n",
    "            corr['asis'] = abs(np.corrcoef(df[i], df[label_name])[1][0])\n",
    "\n",
    "            # log and sqrt\n",
    "            if all((df[i]>=0)):\n",
    "                corr['log'] = abs(np.corrcoef(np.log(df[i] + 0.00001), df[label_name])[1][0])\n",
    "                corr['sqrt'] = abs(np.corrcoef(np.sqrt(df[i]), df[label_name])[1][0])\n",
    "            else:\n",
    "                corr['log'] = 0 \n",
    "                corr['sqrt'] = 0 \n",
    "\n",
    "            #pow2 correlation\n",
    "            corr['pow2'] = abs(np.corrcoef(np.power(df[i].subtract(df[i].mean())/df[i].std(), 2), df[label_name])[1][0])\n",
    "            \n",
    "            # ====================================================================\n",
    "            # select highest correlation \n",
    "            max_corr_type = max(corr, key=corr.get)\n",
    "\n",
    "            if max_corr_type == 'sqrt':\n",
    "                df[i] = np.sqrt(df[i]) # sqrt\n",
    "            elif max_corr_type == 'pow2':\n",
    "                df[i] = np.power(df[i],2) # power 2\n",
    "            elif max_corr_type == 'log':\n",
    "                df[i] = np.log(df[i] + 0.00001) # log      \n",
    "            else:\n",
    "                pass # for asis\n",
    "\n",
    "        return df\n",
    "        \n",
    "        \"\"\"\n",
    "        Objective: Transforms numerical values in a way that it will increase model accuracy.\n",
    "        try asis, sqrt, log, power(2) \n",
    "        inputs:\n",
    "        1. Dataframe df: Pandas dataframe \n",
    "        \n",
    "         outputs:\n",
    "        1. Dataframe df with transformed values\n",
    "        \"\"\"\n",
    "    \n",
    "    def create_dummies(self, df, label_name):\n",
    "        \n",
    "        self.df = df\n",
    "        self.label_name = label_name\n",
    "        \n",
    "        categorical_cols = df.select_dtypes(include = ['object']).columns\n",
    "        for i in categorical_cols:\n",
    "            \n",
    "            if i != label_name:\n",
    "                df_new = pd.get_dummies(df[i], drop_first=True) # dummy variables\n",
    "                df = pd.concat([df, df_new], axis = 1) # join to existing dataset \n",
    "                df.drop([i], axis = 1, inplace=True) # drop original variable after dummy var is made\n",
    "                \n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "        return df\n",
    "\n",
    "        \"\"\"\n",
    "        Objective: Creates dummy variables for categorical variables - not for class\n",
    "        \n",
    "        Inputs:\n",
    "        1. Dataframe df: Pandas dataframe\n",
    "        \n",
    "        Outputs:\n",
    "        1. Dataframe df with dummy variables\n",
    "        \"\"\"\n",
    "\n",
    "    def inspect_multicollinearity(self, df, target_name, threshold):\n",
    "        \"\"\"\n",
    "        this function will help to check whether there is multicollinearity among  independent varialbes incoperate with vif score\n",
    "        \"\"\"\n",
    "        all_input_var = list(set(df.columns.tolist()) - set([target_name]))\n",
    "        vif = pd.concat([pd.DataFrame(all_input_var), pd.DataFrame([variance_inflation_factor(df[all_input_var].values, ix) for ix in range(df[all_input_var].shape[1])])], axis = 1)\n",
    "        vif.columns = ['variable', 'vif_score']\n",
    "        drop_list  = vif.loc[vif.vif_score > threshold, 'variable'].tolist()\n",
    "        df = df.drop(drop_list, axis = 1)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =========================================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
